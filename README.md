# group_5_stairs_project_vmi
Stair Step Detection and Counting
ğŸ“Œ Project Overview
This project focuses on detecting and counting steps in images of stairs using machine learning techniques. The goal is to develop a model that accurately predicts the number of steps in an image, which can be useful for applications in navigation, accessibility, and robotics.

We implemented four different models and compared their performance using Mean Absolute Error (MAE) as the primary evaluation metric. While Random Forest performed well on the training and test sets, it showed high MAE on the validation set, indicating potential overfitting.

ğŸ“‚ Dataset
The dataset consists of images of stairs with labeled step counts. Each image undergoes preprocessing before being fed into the model.

ğŸ”¹ Data Processing Steps:
Image resizing and normalization

Feature extraction (e.g., edge detection, contour analysis)

Splitting into train, test, and validation sets

ğŸ› ï¸ Models Used
We tested four different machine learning models:

Random Forest ğŸŒ³ (Best performance on training/test but high validation error)

Linear Regression ğŸ“ˆ

Support Vector Regression (SVR) ğŸ¤–

K-Nearest Neighbors (KNN) ğŸ”

The performance was evaluated using MAE, which measures how far the predicted step count is from the actual count.

ğŸ“Š Results & Evaluation
Train & Test Performance: Random Forest had the lowest MAE.

Validation Performance: Higher MAE, indicating possible overfitting.

Key Findings:

MAE was chosen over accuracy because step counting is a regression problem, not classification.

Small step count errors are tolerable, making MAE a better metric than MSE (which penalizes large errors too harshly).

ğŸ”§ How to Run the Project
1ï¸âƒ£ Install Dependencies
bash
Copier
Modifier
pip install -r requirements.txt
2ï¸âƒ£ Run the Model
bash
Copier
Modifier
python train_model.py
3ï¸âƒ£ Test on New Images
bash
Copier
Modifier
python predict.py --image path/to/image.jpg
ğŸ” Future Improvements
âœ” Implement cross-validation to better estimate generalization performance.
âœ” Use feature engineering techniques to improve robustness.
âœ” Explore ensemble models to reduce overfitting.

ğŸ“œ License
This project is open-source and available under the MIT License.

